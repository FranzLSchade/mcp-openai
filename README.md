<div align="center">
  <h1>ùîê&nbsp;&nbsp;mpc-openai&nbsp;&nbsp;‚úß</h1>
  <p><em>MCP Client with OpenAI compatible API</em></p>
</div>

> Model Context Protocol (MCP) is an open protocol that standardizes how applications provide context to LLMs. Think of MCP like a USB-C port for AI applications.
>
> ‚Äî [https://modelcontextprotocol.io](https://modelcontextprotocol.io)

______________________________________________________________________

> [!WARNING]: This project is still in the early stages of development. Support is not planned.

This is a MCP **client** (not a server). It is meant to be used as a library for building LLMs UI that support MCP through an OpenAI compatible API. This opens the door to locally runnable inference engines (vLLM, Ollama, TGI, llama.cpp, LMStudio, ...) that support providing support for the OpenAI API (chat completion, tool calls, etc.).

<!--TODO: mermaid diagram-->

<!--TODO: usage-->
